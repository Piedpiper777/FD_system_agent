"""
LSTMé¢„æµ‹å¼‚å¸¸æ£€æµ‹æ¨¡å— - å¼‚å¸¸æ£€æµ‹å™¨
å®ç°å®æ—¶å¼‚å¸¸æ£€æµ‹åŠŸèƒ½
"""

import mindspore as ms
import numpy as np
from typing import Optional, Dict, Any, Union, Tuple, List
from pathlib import Path
import logging
from datetime import datetime

from .model_builder import ModelBuilder
from .threshold_calculator import ThresholdCalculator
from .data_processor import DataProcessor


class AnomalyDetector:
    """
    å®æ—¶å¼‚å¸¸æ£€æµ‹å™¨

    è´Ÿè´£ï¼š
    - åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œé˜ˆå€¼
    - å®æ—¶é¢„å¤„ç†è¾“å…¥æ•°æ®
    - æ‰§è¡Œå¼‚å¸¸æ£€æµ‹
    - è®°å½•å¼‚å¸¸ä¿¡æ¯
    """

    def __init__(self, model_path: Union[str, Path],
                 threshold_path: Union[str, Path],
                 scaler_params: Dict[str, np.ndarray],
                 sequence_length: int = 50):
        """
        åˆå§‹åŒ–å¼‚å¸¸æ£€æµ‹å™¨

        Args:
            model_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
            threshold_path: é˜ˆå€¼æ–‡ä»¶è·¯å¾„
            scaler_params: æ ‡å‡†åŒ–å‚æ•°
            sequence_length: åºåˆ—é•¿åº¦
        """
        self.sequence_length = sequence_length
        self.model = None
        self.threshold_calculator = None
        self.scaler_params = scaler_params

        # å†å²æ•°æ®ç¼“å†²åŒºï¼ˆç”¨äºæ„å»ºåºåˆ—ï¼‰
        self.data_buffer = []

        # æ—¥å¿—è®°å½•å™¨
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.INFO)

        # åŠ è½½ç»„ä»¶
        self._load_model(model_path)
        self._load_threshold(threshold_path)

        print(f"âœ… å¼‚å¸¸æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"  - æ¨¡å‹: {model_path}")
        print(f"  - é˜ˆå€¼: {threshold_path}")
        print(f"  - åºåˆ—é•¿åº¦: {sequence_length}")

    def _load_model(self, model_path: Union[str, Path]):
        """åŠ è½½æ¨¡å‹"""
        try:
            self.model = ms.load_checkpoint(str(model_path))
            print(f"ğŸ“‚ æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
        except Exception as e:
            raise ValueError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    def _load_threshold(self, threshold_path: Union[str, Path]):
        """åŠ è½½é˜ˆå€¼"""
        self.threshold_calculator = ThresholdCalculator()
        self.threshold_calculator.load_threshold(threshold_path)

    def preprocess_online(self, new_data: Union[np.ndarray, List, Dict]) -> np.ndarray:
        """
        å¯¹å®æ—¶æ•°æ®è¿›è¡Œé¢„å¤„ç†

        Args:
            new_data: æ–°æ•°æ®ï¼ˆå•ä¸ªæ ·æœ¬æˆ–æ‰¹æ¬¡ï¼‰

        Returns:
            é¢„å¤„ç†åçš„æ•°æ®
        """
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        if isinstance(new_data, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼ŒæŒ‰ç‰¹å¾é¡ºåºæå–
            feature_names = self.scaler_params.get('feature_names', [])
            if feature_names:
                data_array = np.array([new_data.get(name, 0) for name in feature_names])
            else:
                data_array = np.array(list(new_data.values()))
        elif isinstance(new_data, list):
            data_array = np.array(new_data)
        else:
            data_array = np.array(new_data)

        # ç¡®ä¿æ˜¯äºŒç»´æ•°ç»„
        if data_array.ndim == 1:
            data_array = data_array.reshape(1, -1)

        # æ ‡å‡†åŒ–
        if 'mean' in self.scaler_params and 'scale' in self.scaler_params:
            data_array = (data_array - self.scaler_params['mean']) / self.scaler_params['scale']

        return data_array

    def update_buffer(self, new_data: np.ndarray):
        """
        æ›´æ–°æ•°æ®ç¼“å†²åŒº

        Args:
            new_data: æ–°æ•°æ® (n_features,)
        """
        self.data_buffer.append(new_data.flatten())

        # ä¿æŒç¼“å†²åŒºå¤§å°
        if len(self.data_buffer) > self.sequence_length:
            self.data_buffer.pop(0)

    def create_sequence(self) -> Optional[np.ndarray]:
        """
        ä»ç¼“å†²åŒºåˆ›å»ºåºåˆ—

        Returns:
            åºåˆ—æ•°æ®æˆ–Noneï¼ˆå¦‚æœæ•°æ®ä¸è¶³ï¼‰
        """
        if len(self.data_buffer) < self.sequence_length:
            return None

        # å–æœ€è¿‘çš„sequence_lengthä¸ªæ ·æœ¬
        sequence_data = np.array(self.data_buffer[-self.sequence_length:])
        return sequence_data.reshape(1, self.sequence_length, -1)  # (1, seq_len, n_features)

    def detect(self, input_data: Union[np.ndarray, List, Dict]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå¼‚å¸¸æ£€æµ‹

        Args:
            input_data: è¾“å…¥æ•°æ®

        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        # é¢„å¤„ç†æ•°æ®
        processed_data = self.preprocess_online(input_data)

        # æ›´æ–°ç¼“å†²åŒº
        self.update_buffer(processed_data[0])  # å‡è®¾æ¯æ¬¡åªå¤„ç†ä¸€ä¸ªæ ·æœ¬

        # åˆ›å»ºåºåˆ—
        sequence = self.create_sequence()
        if sequence is None:
            return {
                'is_anomaly': False,
                'residual_score': 0.0,
                'confidence': 0.0,
                'status': 'collecting_data',
                'message': f'æ•°æ®ä¸è¶³ï¼Œè¿˜éœ€è¦ {self.sequence_length - len(self.data_buffer)} ä¸ªæ ·æœ¬'
            }

        # æ¨¡å‹é¢„æµ‹
        try:
            input_tensor = ms.Tensor(sequence, ms.float32)
            prediction = self.model(input_tensor)
            prediction = prediction.asnumpy()[0]  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„é¢„æµ‹

            # è¿™é‡Œéœ€è¦å®é™…çš„ä¸‹ä¸€æ—¶åˆ»ç›®æ ‡å€¼ï¼Œä½†åœ¨åœ¨çº¿æ£€æµ‹ä¸­é€šå¸¸ä¸å¯ç”¨
            # å› æ­¤æˆ‘ä»¬ä½¿ç”¨é¢„æµ‹å€¼æœ¬èº«ä½œä¸º"å®é™…å€¼"çš„è¿‘ä¼¼ï¼Œæˆ–è€…è¿”å›é¢„æµ‹ç»“æœ
            # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦ç­‰å¾…ä¸‹ä¸€ä¸ªæ—¶é—´ç‚¹çš„çœŸå®å€¼

            # ç”±äºåœ¨çº¿æ£€æµ‹æ—¶æ²¡æœ‰çœŸå®å€¼ï¼Œæˆ‘ä»¬è¿”å›é¢„æµ‹ä¿¡æ¯
            result = {
                'prediction': prediction.tolist(),
                'residual_score': None,  # åœ¨çº¿æ£€æµ‹æ—¶æ— æ³•è®¡ç®—æ®‹å·®
                'is_anomaly': None,      # åœ¨çº¿æ£€æµ‹æ—¶æ— æ³•åˆ¤æ–­å¼‚å¸¸
                'confidence': 0.5,       # é»˜è®¤ç½®ä¿¡åº¦
                'status': 'prediction_only',
                'timestamp': datetime.now().isoformat(),
                'message': 'åœ¨çº¿é¢„æµ‹å®Œæˆï¼Œç­‰å¾…å®é™…å€¼è¿›è¡Œå¼‚å¸¸åˆ¤æ–­'
            }

        except Exception as e:
            result = {
                'is_anomaly': False,
                'residual_score': 0.0,
                'confidence': 0.0,
                'status': 'error',
                'message': f'æ£€æµ‹å¤±è´¥: {str(e)}',
                'timestamp': datetime.now().isoformat()
            }

        return result

    def detect_with_actual(self, input_sequence: np.ndarray,
                          actual_next: np.ndarray) -> Dict[str, Any]:
        """
        ä½¿ç”¨å®é™…å€¼è¿›è¡Œå¼‚å¸¸æ£€æµ‹ï¼ˆç¦»çº¿è¯„ä¼°æˆ–æœ‰çœŸå®å€¼çš„åœºæ™¯ï¼‰

        Args:
            input_sequence: è¾“å…¥åºåˆ— (seq_len, n_features)
            actual_next: å®é™…çš„ä¸‹ä¸€æ—¶åˆ»å€¼ (n_features,)

        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        try:
            # æ¨¡å‹é¢„æµ‹
            input_tensor = ms.Tensor(input_sequence.reshape(1, *input_sequence.shape), ms.float32)
            prediction = self.model(input_tensor)
            prediction = prediction.asnumpy()[0]

            # è®¡ç®—å¼‚å¸¸åˆ†æ•°
            residual_score, is_anomaly = self.threshold_calculator.detect_anomaly(
                prediction, actual_next
            )

            # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºé˜ˆå€¼çš„è·ç¦»ï¼‰
            threshold = self.threshold_calculator.threshold
            confidence = min(1.0, max(0.0, 1.0 - (residual_score - threshold) / threshold))

            result = {
                'prediction': prediction.tolist(),
                'actual': actual_next.tolist(),
                'residual_score': float(residual_score),
                'is_anomaly': bool(is_anomaly),
                'confidence': float(confidence),
                'threshold': float(threshold),
                'status': 'success',
                'timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            result = {
                'is_anomaly': False,
                'residual_score': 0.0,
                'confidence': 0.0,
                'status': 'error',
                'message': f'æ£€æµ‹å¤±è´¥: {str(e)}',
                'timestamp': datetime.now().isoformat()
            }

        return result

    def log_anomaly(self, anomaly_info: Dict[str, Any], log_file: Optional[str] = None):
        """
        è®°å½•å¼‚å¸¸ä¿¡æ¯

        Args:
            anomaly_info: å¼‚å¸¸ä¿¡æ¯å­—å…¸
            log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
        """
        if anomaly_info.get('is_anomaly'):
            log_message = (
                f"[{anomaly_info['timestamp']}] å¼‚å¸¸æ£€æµ‹: "
                f"æ®‹å·®åˆ†æ•°={anomaly_info['residual_score']:.4f}, "
                f"é˜ˆå€¼={anomaly_info.get('threshold', 'N/A')}, "
                f"ç½®ä¿¡åº¦={anomaly_info['confidence']:.4f}"
            )

            self.logger.warning(log_message)

            # å¦‚æœæŒ‡å®šäº†æ—¥å¿—æ–‡ä»¶ï¼Œå†™å…¥æ–‡ä»¶
            if log_file:
                try:
                    with open(log_file, 'a', encoding='utf-8') as f:
                        f.write(log_message + '\n')
                except Exception as e:
                    self.logger.error(f"æ—¥å¿—å†™å…¥å¤±è´¥: {e}")

    def get_detector_info(self) -> Dict[str, Any]:
        """
        è·å–æ£€æµ‹å™¨ä¿¡æ¯

        Returns:
            æ£€æµ‹å™¨ä¿¡æ¯å­—å…¸
        """
        return {
            'sequence_length': self.sequence_length,
            'buffer_size': len(self.data_buffer),
            'threshold': self.threshold_calculator.threshold if self.threshold_calculator else None,
            'residual_method': self.threshold_calculator.residual_method if self.threshold_calculator else None,
            'feature_names': self.scaler_params.get('feature_names', []),
            'model_loaded': self.model is not None,
            'threshold_loaded': self.threshold_calculator is not None
        }

    def reset_buffer(self):
        """é‡ç½®æ•°æ®ç¼“å†²åŒº"""
        self.data_buffer = []
        print("ğŸ”„ æ•°æ®ç¼“å†²åŒºå·²é‡ç½®")